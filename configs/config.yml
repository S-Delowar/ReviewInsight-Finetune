paths:
  raw_data: artifacts/data/raw/Electronics_5.json
  preprocessed_data: artifacts/data/processed/processed_product_reviews.parquet
  generated_data: artifacts/data/generated/instruction_answers.jsonl

generation:
  model: gpt-4o-mini
  temperature: 0.3

huggingface:
  dataset_repo: sdelowar2/product_reviews_insight_10k
  finetuned_model_repo: sdelowar2/mistral-7B-reviews-insight-lora

fine_tune:
  base_model:
    name: "mistralai/Mistral-7B-Instruct-v0.2"
    load_in_4bit: True
    max_length: 512

  dataset:
    split_ratio: [0.8, 0.1, 0.1]   # train, val, test

  training:
    output_dir: "artifacts/checkpoints"
    num_train_epochs: 3
    learning_rate: 3e-4
    lr_scheduler_type: "linear"
    per_device_train_batch_size: 2
    gradient_accumulation_steps: 8
    logging_steps: 20
    optim: "adamw_8bit"
    weight_decay: 0.01
    warmup_steps: 10
    seed: 0
    eval_strategy: "none"
    per_device_eval_batch_size: 1
    save_strategy: "epoch"

  peft:
    r: 16
    lora_alpha: 32
    lora_dropout: 0.05
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"]
    bias: "none"
    task_type: "CAUSAL_LM"

  wandb:
    project: "llm-finetune-review-insight"
    run_name: "review-insight-training"